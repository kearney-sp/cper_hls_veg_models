{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c7c05-fa56-4883-9ebe-c0e70fe541ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d32240-1f30-431a-9aff-f415af28a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as riox\n",
    "import xarray as xr\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f48fa6-e075-4f42-a8f1-250832b968b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4794f04-6e0b-4e92-b78f-be35f7027cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlsstack.hls_funcs.indices import ndvi_func\n",
    "from hlsstack.hls_funcs.predict import pred_cp\n",
    "from hlsstack.models.load import load_model\n",
    "from hlsstack.hls_funcs.smooth import smooth_xr, despike_ts_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927fc5d-5165-481a-ba68-87af13b88c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert(1, '/project/cper_neon_aop/hls_nrt_utils/hlsstack/hls_funcs')\n",
    "#sys.path.insert(1, '/project/cper_neon_aop/hls_nrt_utils/hlsstack/models')\n",
    "#from predict import pred_bm, pred_bm_se\n",
    "#from indices import ndvi_func\n",
    "#from smooth import smooth_xr, despike_ts_xr\n",
    "#from load import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9464166-38e8-4f46-b32a-4cc763b9a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f73878-4927-4eab-9403-2ac3d863e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'cper'\n",
    "\n",
    "inDIR = os.path.join('/90daydata/cper_neon_aop/cper_hls_veg_models/data/lmf_cper')\n",
    "outDIR = '/90daydata/cper_neon_aop/hls_nrt/cper/lmf_cp/'\n",
    "if not os.path.exists(outDIR):\n",
    "    os.mkdir(outDIR)\n",
    "overwrite=False\n",
    "\n",
    "# the path to a shapefile with CPER pasture boundaries\n",
    "cper_f = '/project/cper_neon_aop/cper_hls_veg_models/data/ground/boundaries/cper_pastures_2017_dissolved.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777ae0c-a858-4cfb-a140-a3ee564396d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the pasture boundaries to be converted into an xarray mask\n",
    "cper = gpd.read_file(cper_f).to_crs(32613)\n",
    "#cper_info = cper[['Pasture', 'geometry']].reset_index(drop=True).reset_index().rename(columns={'index': 'id'})\n",
    "#past_dict = {row.id+1: row.Pasture for _, row in cper_info.iterrows()}\n",
    "#past_dict[0] = 'UNK'\n",
    "#cper_mask_shp = [(row.geometry, row.id+1) for _, row in cper_info.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50f7453-1df8-47f4-9fd3-00eba5afcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "import dask\n",
    "from jupyter_server import serverapp\n",
    "try:\n",
    "    jupServer = [x for x in serverapp.list_running_servers()][0]\n",
    "    dask.config.set({'distributed.dashboard.link': 'https://atlas-ood.hpc.msstate.edu' + jupServer['base_url'] + 'proxy/{port}/status'})\n",
    "except:\n",
    "    dask.config.set({'distributed.dashboard.link': 'https://atlas-ood.hpc.msstate.edu' + '/node/atlas-0024/6142/' + 'proxy/{port}/status'})\n",
    "    pass\n",
    "cluster = LocalCluster(n_workers=48)\n",
    "client = Client(cluster)\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31f9ce-fc19-4219-a81f-84822ba46d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09234b74-0bde-4edf-807c-4fbe31335c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance away from the FBEWMA that data should be removed.\n",
    "DELTA = 250\n",
    "\n",
    "# clip data above this value:\n",
    "HIGH_CLIP = 10000\n",
    "\n",
    "# clip data below this value:\n",
    "LOW_CLIP = 0\n",
    "\n",
    "# random values above this trigger a spike:\n",
    "RAND_HIGH = 0.98\n",
    "\n",
    "# random values below this trigger a negative spike:\n",
    "RAND_LOW = 0.02\n",
    "\n",
    "# How many samples to run the FBEWMA over.\n",
    "SPAN = 45\n",
    "\n",
    "# spike amplitude\n",
    "SPIKE = 2\n",
    "\n",
    "\n",
    "def clip_data(unclipped, high_clip, low_clip):\n",
    "    ''' Clip unclipped between high_clip and low_clip. \n",
    "    unclipped contains a single column of unclipped data.'''\n",
    "    \n",
    "    # convert to np.array to access the np.where method\n",
    "    np_unclipped = np.array(unclipped)\n",
    "    # clip data above HIGH_CLIP or below LOW_CLIP\n",
    "    cond_high_clip = (np_unclipped > HIGH_CLIP) | (np_unclipped < LOW_CLIP)\n",
    "    np_clipped = np.where(cond_high_clip, np.nan, np_unclipped)\n",
    "    return np_clipped.tolist()\n",
    "\n",
    "\n",
    "def create_sample_data():\n",
    "    ''' Create sine wave, amplitude +/-2 with random spikes. '''\n",
    "    x = np.linspace(0, 2*np.pi, 1000)\n",
    "    y = 2 * np.sin(x)\n",
    "    df = pd.DataFrame(list(zip(x,y)), columns=['x', 'y'])\n",
    "    df['rand'] = np.random.random_sample(len(x),)\n",
    "    # create random positive and negative spikes\n",
    "    cond_spike_high = (df['rand'] > RAND_HIGH)\n",
    "    df['spike_high'] = np.where(cond_spike_high, SPIKE, 0)\n",
    "    cond_spike_low = (df['rand'] < RAND_LOW)\n",
    "    df['spike_low'] = np.where(cond_spike_low, -SPIKE, 0)\n",
    "    df['y_spikey'] = df['y'] + df['spike_high'] + df['spike_low']\n",
    "    return df\n",
    "\n",
    "\n",
    "def ewma_fb(df_column, span):\n",
    "    ''' Apply forwards, backwards exponential weighted moving average (EWMA) to df_column. '''\n",
    "    # Forwards EWMA.\n",
    "    fwd = pd.Series.ewm(df_column, span=span).mean()\n",
    "    # Backwards EWMA.\n",
    "    bwd = pd.Series.ewm(df_column[::-1],span=10).mean()\n",
    "    # Add and take the mean of the forwards and backwards EWMA.\n",
    "    stacked_ewma = np.vstack(( fwd, bwd[::-1] ))\n",
    "    fb_ewma = np.mean(stacked_ewma, axis=0)\n",
    "    return fb_ewma\n",
    "    \n",
    "    \n",
    "def remove_outliers(spikey, fbewma, delta):\n",
    "    ''' Remove data from df_spikey that is > delta from fbewma. '''\n",
    "    np_spikey = np.array(spikey)\n",
    "    np_fbewma = np.array(fbewma)\n",
    "    cond_delta = (np.abs(np_spikey-np_fbewma) > delta)\n",
    "    np_remove_outliers = np.where(cond_delta, np.nan, np_spikey)\n",
    "    return np_remove_outliers\n",
    "\n",
    "    \n",
    "def main():\n",
    "    df = create_sample_data()\n",
    "\n",
    "    df['y_clipped'] = clip_data(df['y_spikey'].tolist(), HIGH_CLIP, LOW_CLIP)\n",
    "    df['y_ewma_fb'] = ewma_fb(df['y_clipped'], SPAN)\n",
    "    df['y_remove_outliers'] = remove_outliers(df['y_clipped'].tolist(), df['y_ewma_fb'].tolist(), DELTA)\n",
    "    df['y_interpolated'] = df['y_remove_outliers'].interpolate()\n",
    "    \n",
    "    ax = df.plot(x='x', y='y_spikey', color='blue', alpha=0.5)\n",
    "    ax2 = df.plot(x='x', y='y_interpolated', color='black', ax=ax)\n",
    "    \n",
    "def remove_spikes(ts, HIGH_CLIP, LOW_CLIP, SPAN, DELTA):\n",
    "    df = pd.DataFrame({'y_spikey': ts})\n",
    "    #df['y_spikey'] = df['y_spikey'].interpolate()\n",
    "    df['y_clipped'] = clip_data(df['y_spikey'].tolist(), HIGH_CLIP, LOW_CLIP)\n",
    "    df['y_ewma_fb'] = ewma_fb(df['y_clipped'], SPAN)\n",
    "    df['y_remove_outliers'] = remove_outliers(df['y_clipped'].tolist(), df['y_ewma_fb'].tolist(), DELTA)\n",
    "    df['y_interpolated'] = df['y_remove_outliers'].interpolate()\n",
    "    return df['y_remove_outliers'].isnull().astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46c44b-f6af-4a4c-b28c-510b765b4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def despike_lmf_mask(band_ts, mask_pos_spikes=False, min_prominence=0.2, low_prominence=0.05, max_width=None):\n",
    "    try:\n",
    "        if mask_pos_spikes:\n",
    "            ts = pd.Series(band_ts).interpolate()\n",
    "        else:\n",
    "            ts = pd.Series(band_ts*-1.0).interpolate()\n",
    "        pks = find_peaks(ts, prominence=low_prominence, width=[0, max_width])\n",
    "        for i in range(len(pks[0])):\n",
    "            if pks[1]['prominences'][i] > min_prominence:\n",
    "                #print(i)\n",
    "                pk = pks[0][i]\n",
    "                if i > 0 and pks[1]['prominences'][i-1] < min_prominence:\n",
    "                    left_b = max(pks[1]['left_bases'][i], pks[1]['right_bases'][i-1])\n",
    "                else:\n",
    "                    left_b = pks[1]['left_bases'][i]\n",
    "                if i < len(pks) and pks[1]['prominences'][i+1] < min_prominence:\n",
    "                    right_b = min(pks[1]['right_bases'][i], pks[1]['left_bases'][i+1])\n",
    "                else:\n",
    "                    right_b = pks[1]['right_bases'][i]\n",
    "\n",
    "                if max_width is None:\n",
    "                    drop_pk = False\n",
    "                else:\n",
    "                    if (right_b - left_b) > max_width:\n",
    "                        drop_pk = True\n",
    "                    else:\n",
    "                        drop_pk = False\n",
    "                if not drop_pk:\n",
    "                    ts_sub = ts[left_b:right_b]\n",
    "            \n",
    "                    slp, xcpt = np.polyfit([left_b, right_b], ts_sub[[left_b, right_b-1]], 1)\n",
    "                    trend = ts_sub.iloc[0] + slp*np.arange(0, len(ts_sub))\n",
    "                \n",
    "                    trend_diff = ts_sub - trend\n",
    "                    ts_sub_masked = ts_sub.copy()\n",
    "                    ts_sub_masked[trend_diff > 0] = np.nan\n",
    "                    ts.loc[ts_sub_masked[ts_sub_masked.isnull()].index] = np.nan\n",
    "                else:\n",
    "                    continue\n",
    "        return ts.isnull().astype(int).values\n",
    "    except (KeyError, IndexError) as e:\n",
    "        return np.ones_like(band_ts)\n",
    "        \n",
    "\n",
    "def despike_lmf_mask_xr(dat, dims, kwargs):\n",
    "    xr_mask = xr.apply_ufunc(remove_spikes,\n",
    "                             dat.stack(z = ['y', 'x']).chunk({'time': -1, 'z': 20}),\n",
    "                             kwargs=kwargs,\n",
    "                             input_core_dims=[dims],\n",
    "                             output_core_dims=[dims],\n",
    "                             dask='parallelized', vectorize=True,\n",
    "                             output_dtypes=[int])\n",
    "    return xr_mask.transpose('time', 'z').unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fbc7ea-58d3-4b2c-8cbb-5f8ab8e91d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 174.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for yr in tqdm(range(2000, 2015)):\n",
    "    out_path_exists = os.path.exists(os.path.join(outDIR, \n",
    "                                              'cper_lmf_cp_'+str(yr)+'.nc'))\n",
    "    in_path_exists = os.path.exists(os.path.join(inDIR, 'CPER_'+str(yr)+'.Landsat_MODIS_STARFM.nc'))\n",
    "    if not overwrite and out_path_exists:\n",
    "        continue\n",
    "    elif not in_path_exists:\n",
    "        continue\n",
    "    else:\n",
    "        print(yr)\n",
    "        nc_f = os.path.join(inDIR, 'CPER_'+str(yr)+'.Landsat_MODIS_STARFM.nc')\n",
    "        hls_ds = xr.open_dataset(nc_f, chunks={'DOY': -1, 'y': 20, 'x': 20})\n",
    "        \n",
    "        if hls_ds.rio.crs != cper.crs:\n",
    "            hls_ds = hls_ds.rio.reproject(cper.crs)\n",
    "        # convert the band coordinate to date\n",
    "        hls_ds['DOY'] = [datetime(yr, 1, 1) + timedelta(days=int(x)-1) for x in hls_ds['DOY'].values]\n",
    "        # rename band coordinate to date\n",
    "        hls_ds = hls_ds.rename({'DOY': 'time'})\n",
    "        # subset to only CPER boundaries\n",
    "        hls_ds = hls_ds.sel(x=slice(cper.total_bounds[0], cper.total_bounds[2] + 30),\n",
    "                            y=slice(cper.total_bounds[3], cper.total_bounds[1] - 30))\n",
    "        \n",
    "        hls_ds = hls_ds.where(hls_ds != -9999)\n",
    "        \n",
    "        hls_ds['NDVI'] = ndvi_func(hls_ds)\n",
    "        hls_ds['NDVI'] = hls_ds['NDVI'].where(hls_ds['NDVI'] > 0)\n",
    "        \n",
    "        ndvi_mask = despike_lmf_mask_xr(hls_ds['NDVI'], dims=['time'], kwargs={'HIGH_CLIP': 1.0,\n",
    "                                                                               'LOW_CLIP': 0.0,\n",
    "                                                                               'SPAN': 2,\n",
    "                                                                               'DELTA': 0.07})\n",
    "        \n",
    "        ndvi_mask_out = ndvi_mask.compute()\n",
    "        \n",
    "        hls_ds = hls_ds.where(ndvi_mask_out==0)\n",
    "        \n",
    "        blue_mask = despike_lmf_mask_xr(hls_ds['BLUE'], dims=['time'], kwargs={'HIGH_CLIP': 10000,\n",
    "                                                                               'LOW_CLIP': 0,\n",
    "                                                                               'SPAN': 20,\n",
    "                                                                               'DELTA': 100})\n",
    "        \n",
    "        blue_mask_out = blue_mask.compute()\n",
    "        \n",
    "        swir2_mask = despike_lmf_mask_xr(hls_ds['SWIR2'], dims=['time'], kwargs={'HIGH_CLIP': 10000,\n",
    "                                                                               'LOW_CLIP': 0,\n",
    "                                                                               'SPAN': 20,\n",
    "                                                                               'DELTA': 200})\n",
    "        \n",
    "        swir2_mask_out = swir2_mask.compute()\n",
    "        \n",
    "        hls_ds = hls_ds.where(blue_mask_out==0)\n",
    "        hls_ds = hls_ds.where(swir2_mask_out==0)             \n",
    "        \n",
    "        dat_out_ndvi_ds = despike_ts_xr(hls_ds['NDVI'],\n",
    "                                   dat_thresh=0.07, \n",
    "                                   mask_outliers=False,\n",
    "                                   iters=2,\n",
    "                                   dims=['time']).persist()\n",
    "        \n",
    "        dat_out_ndvi = smooth_xr(dat_out_ndvi_ds, \n",
    "                               dims=['time'], \n",
    "                               kwargs={'double': True, 'limit': 91})\n",
    "\n",
    "        mod_cp = load_model('cper_cp')\n",
    "        # create biomass array\n",
    "        dat_out_da = pred_cp(dat_out_da_ndvi, model=mod_cp)\n",
    "        dat_out_da.name = 'CP'\n",
    "        \n",
    "        dat_out_da = dat_out_da.rio.write_crs(hls_ds.rio.crs)\n",
    "        dat_out_da = dat_out_da.where(dat_out_da > 0)\n",
    "        dat_out_da = dat_out_da.astype('float32')\n",
    "        dat_out_da = dat_out_da.sortby([\"time\", \"y\", \"x\"]).sortby('y', ascending=False)\n",
    "        \n",
    "        display(dat_out_da)\n",
    "        \n",
    "        dat_out_da.to_netcdf(os.path.join(outDIR, \n",
    "                                          'cper_lmf_cp_'+str(yr)+'.nc'))\n",
    "        os.chmod(os.path.join(outDIR, 'cper_lmf_cp_'+str(yr)+'.nc'), 0o777)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_nrt_env",
   "language": "python",
   "name": "hls_nrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
