{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12ea62-f82b-4efd-bae5-12db3413a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from hlsstack.hls_funcs.smooth import despike_ts, double_savgol\n",
    "from hlsstack.hls_funcs.masks import bolton_mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167e485-10c5-4083-bb64-0b5054b17d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_csv('../data/raw_tmp/ts_raw_vor_plot.csv', parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f50e6e-b7a7-4edb-8dfd-8a980e40f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['duplicated'] = df_ts.duplicated(subset=['Id', 'Date'], keep=False)\n",
    "df_ts['dup_first'] = df_ts.duplicated(subset=['Id', 'Date'], keep='first')\n",
    "df_ts['dup_last'] = df_ts.duplicated(subset=['Id', 'Date'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b15c3-5f35-4a75-a025-ee77d9bf20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df_ts[\n",
    "(~df_ts['duplicated']) |\n",
    "(df_ts['Date'].dt.month < 3) & df_ts['duplicated'] & (~df_ts['dup_last']) |\n",
    "(df_ts['Date'].dt.month > 10) & df_ts['duplicated'] & (~df_ts['dup_first'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca4708-4ba9-4d7b-8346-a385f89ce87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.duplicated(subset=['Id', 'Date']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25ddfe-21ac-4daa-b559-53f4dfb85405",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [x for x in df_ts.columns[2:] if '_smooth' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637b704-5d9c-4f43-836f-49da29ed775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothed data for a single plot\n",
    "plot = '20SE_P3'\n",
    "fig, axs = plt.subplots(figsize=(20, 3*len(cols)), nrows=len(cols))\n",
    "for idx, ax in enumerate(axs):\n",
    "    df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=cols[idx], ax=ax, c='black', s=10, alpha=0.5)\n",
    "    df_ts[df_ts['Id'] == plot].plot(x='Date', y=cols[idx] + '_smooth', ax=ax, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11116c49-5cd2-4606-b80d-62d02f3560ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['NDVI_dv1'] = df_ts.groupby([df_ts['Date'].dt.year, 'Id'])['NDVI_smooth'].transform(lambda x: x.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ea63d-d3ff-4664-94aa-481e8e22300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot updated smooth with start of season (blue) and peak of season (red)\n",
    "plot = '20SE_P3'\n",
    "var1 = 'NDVI'\n",
    "var2 = 'NDVI_dv1'\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 6), nrows=2)\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var1, ax=axs[0], c='black', s=10, alpha=0.5)\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth', ax=axs[0], c='red')\n",
    "\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 , ax=axs[1], c='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023d108-6d93-4532-8764-b5d53d8b7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot updated smooth with start of season (blue) and peak of season (red)\n",
    "plot = '20SE_P3'\n",
    "var1 = 'SATVI'\n",
    "var2 = 'MTVI1'\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 6), nrows=2)\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var1, ax=axs[0], c='blue', s=10)\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth', ax=axs[0], c='blue')\n",
    "\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var2, ax=axs[1], c='red', s=10)\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth', ax=axs[1], c='red')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axvline(pd.Timestamp('2016-06-12'), color='g')\n",
    "    ax.axvline(pd.Timestamp('2016-06-30'), color='r')\n",
    "    ax.axvline(pd.Timestamp('2016-10-5'), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4cdd2-3180-405f-853e-b4cbae08c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae344ab-8eb2-44cc-bf2b-468f9a6f42d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e48d3d-7daa-44b7-91e8-acde9d1ed658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bolton_mask(blue, swir2):\n",
    "\n",
    "    indices = blue.index\n",
    "\n",
    "    ts_blue = blue.values\n",
    "    ts_swir2 = swir2.values\n",
    "    \n",
    "    def cloud_outlier_mask(da_blue):\n",
    "        blue_ts = da_blue / 10000.0\n",
    "        cloud_mask = np.zeros_like(blue_ts)\n",
    "        for idx in range(len(blue_ts)):\n",
    "            if not np.isnan(blue_ts[idx]):\n",
    "                idx_clear = np.where(~np.isnan(blue_ts))[0]\n",
    "                if idx == np.min(idx_clear):\n",
    "                    continue\n",
    "                else:\n",
    "                    idx_pre = np.max(idx_clear[idx_clear < idx])\n",
    "                    blue_diff = blue_ts[idx] - blue_ts[idx_pre]\n",
    "                    cloud_thresh = 0.03 * (1 + (idx - idx_pre) / 30)\n",
    "                    if blue_diff > cloud_thresh:\n",
    "                        blue_ts[idx] = np.nan\n",
    "                        cloud_mask[idx] = 1\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "        return cloud_mask\n",
    "\n",
    "    def shadow_outlier_mask(da_swir2):\n",
    "        swir2_ts = da_swir2.copy()\n",
    "        shadow_mask = np.zeros_like(swir2_ts)\n",
    "        for idx in range(len(swir2_ts)):\n",
    "            if not np.isnan(swir2_ts[idx]):\n",
    "                idx_clear = np.where(~np.isnan(swir2_ts))[0]\n",
    "                if idx == np.min(idx_clear):\n",
    "                    continue\n",
    "                elif idx == np.max(idx_clear):\n",
    "                    try:\n",
    "                        idx_pre = idx_clear[idx_clear < idx][-1]\n",
    "                        idx_pre2 = idx_clear[idx_clear < idx][-2]\n",
    "                        y = np.array([swir2_ts[idx_pre2], swir2_ts[idx_pre]])\n",
    "                        x = np.array([idx_pre2, idx_pre])\n",
    "                        dx = np.diff(x)\n",
    "                        dy = np.diff(y)\n",
    "                        slope = dy / dx\n",
    "                        swir2_interp = swir2_ts[idx_pre] + slope[0] * (idx - idx_pre)\n",
    "                        swir2_diff = swir2_interp - swir2_ts[idx]\n",
    "                        if (swir2_ts[idx_pre] - swir2_ts[idx_pre2]) == 0:\n",
    "                            shadow_val = np.nan\n",
    "                        else:\n",
    "                            shadow_val = swir2_diff / (swir2_ts[idx_pre] - swir2_ts[idx_pre2])\n",
    "                        if (idx - idx_pre2 < 45) & (swir2_diff > 500) & (np.abs(shadow_val) > 2):\n",
    "                            swir2_ts[idx] = np.nan\n",
    "                            shadow_mask[idx] = 1\n",
    "                        else:\n",
    "                            continue\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "                else:\n",
    "                    idx_pre = idx_clear[idx_clear < idx][-1]\n",
    "                    idx_post = idx_clear[idx_clear > idx][0]\n",
    "                    y = np.array([swir2_ts[idx_pre], swir2_ts[idx_post]])\n",
    "                    x = np.array([idx_pre, idx_post])\n",
    "                    dx = np.diff(x)\n",
    "                    dy = np.diff(y)\n",
    "                    slope = dy / dx\n",
    "                    swir2_interp = swir2_ts[idx_pre] + slope[0] * (idx - idx_pre)\n",
    "                    swir2_diff = swir2_interp - swir2_ts[idx]\n",
    "                    if (swir2_ts[idx_post] - swir2_ts[idx_pre]) == 0:\n",
    "                        shadow_val = np.nan\n",
    "                    else:\n",
    "                        shadow_val = swir2_diff / (swir2_ts[idx_post] - swir2_ts[idx_pre])\n",
    "                    if (idx_post - idx_pre < 45) & (swir2_diff > 500) & (np.abs(shadow_val) > 2):\n",
    "                        swir2_ts[idx] = np.nan\n",
    "                        shadow_mask[idx] = 1\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "        return shadow_mask\n",
    "\n",
    "    shadow_outliers = shadow_outlier_mask(ts_swir2)\n",
    "    ts_blue[shadow_outliers == 1]= np.nan\n",
    "    cloud_outliers = cloud_outlier_mask(ts_blue)\n",
    "    mask = np.maximum(cloud_outliers, shadow_outliers)\n",
    "    mask = pd.Series(mask, index=indices)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff4140-b7a5-4f18-8ad0-b9104841c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_smooth(ts, dates, despike=True, dat_thresh=None):\n",
    "    ct_valid = sum(~np.isnan(ts[(dates.dt.month >= 3) & (dates.dt.month <= 10)]))\n",
    "    if 180 / ct_valid > 15:\n",
    "        despike = False\n",
    "    if despike:\n",
    "        if dat_thresh is None:\n",
    "            _dat_thresh = np.ptp(ts.values) * 0.10\n",
    "        else:\n",
    "            _dat_thresh = dat_thresh\n",
    "        ts_ds = despike_ts(ts.values, dat_thresh=_dat_thresh, days_thresh=45)\n",
    "    else:\n",
    "        ts_ds = ts.values\n",
    "    if 180 / ct_valid > 10:\n",
    "        ts_smooth = double_savgol(ts_ds, double=True, window1_max=7, window2=31, limit=91)\n",
    "    elif 180 / ct_valid > 7:\n",
    "         ts_smooth = double_savgol(ts_ds, double=True, window1_max=5, window2=41, limit=91)\n",
    "    elif 180 / ct_valid > 5:\n",
    "         ts_smooth = double_savgol(ts_ds, double=True, window1_max=5, window2=51, limit=91)\n",
    "    else:\n",
    "        ts_smooth = double_savgol(ts_ds, double=False, window2=51, limit=91)\n",
    "    return pd.Series(ts_smooth, ts.index.get_level_values(-1))\n",
    "\n",
    "def set_smooth(ts, dates, despike=True, dat_thresh=None):\n",
    "    if despike:\n",
    "        if dat_thresh is None:\n",
    "            _dat_thresh = np.ptp(ts.values[~np.isnan(ts.values)]) * 0.10\n",
    "        else:\n",
    "            _dat_thresh = dat_thresh\n",
    "        ts_ds = despike_ts(ts.values, dat_thresh=_dat_thresh, days_thresh=45)\n",
    "    ts_smooth = double_savgol(ts_ds, double=True, window1_max=9, window2=41, limit=91)\n",
    "    return pd.Series(ts_smooth, ts.index.get_level_values(-1))\n",
    "\n",
    "# dictionary specifying functions for each vegetation index to calculate and extract\n",
    "veg_list = ['NDVI',\n",
    "    'DFI',\n",
    "    'NDTI',\n",
    "    'SATVI',\n",
    "    'NDII7',\n",
    "    'BAI_126',\n",
    "    'BAI_136',\n",
    "    'BAI_146',\n",
    "    'BAI_236',\n",
    "    'BAI_246',\n",
    "    'BAI_346']\n",
    "\n",
    "# dictionary specifying individual bands to extract\n",
    "band_list = ['BLUE', 'GREEN', 'RED', 'NIR1', 'SWIR1', 'SWIR2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61996e-a87d-4238-971c-56912210bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7ae6e-b06c-4afc-ac7f-b32e7e05796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_bolton = df_ts.groupby('Id').progress_apply(lambda x: bolton_mask_np(x['BLUE'], x['SWIR2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d4163-8e12-4bb9-9f9f-7c00e4407ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts.loc[df_ts[ps_bolton.droplevel(0) == 1.0].index, veg_list + band_list] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff661b09-253f-4087-893f-fa0f107c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "despike_dict = {\n",
    "    'NDVI': 0.05,\n",
    "    'DFI': 2.0,\n",
    "    'NDTI': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47872d29-31a9-44cc-b871-5a7899c46455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# smooth all vegetation indices to gapfill\n",
    "for vegidx in veg_list:\n",
    "    #df_yr_ts[vegidx + '_smooth'] = df_yr_ts.groupby('Id')[vegidx].transform(lambda x: double_savgol(x.values))\n",
    "    vals_smooth = df_ts.groupby('Id').progress_apply(lambda x: set_smooth(x[vegidx], pd.to_datetime(x['Date'])))\n",
    "    df_ts[vegidx + '_smooth2'] = vals_smooth.droplevel(list(np.arange(vals_smooth.index.nlevels-1)))\n",
    "for band in band_list:\n",
    "    #df_yr_ts[band + '_smooth'] = df_yr_ts.groupby('Id')[band].transform(lambda x: double_savgol(x.values))\n",
    "    vals_smooth = df_ts.groupby('Id').progress_apply(lambda x: set_smooth(x[band], pd.to_datetime(x['Date'])))\n",
    "    df_ts[band + '_smooth2'] = vals_smooth.droplevel(list(np.arange(vals_smooth.index.nlevels-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e2044-8f72-41fd-ae57-48261cf5d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot updated smooth with start of season (blue) and peak of season (red)\n",
    "plot = '10S_P1'\n",
    "var1 = 'DFI'\n",
    "var2 = 'NDVI'\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 6), nrows=2)\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var1, ax=axs[0], c='blue', s=15)\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth', ax=axs[0], c='blue')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth2', ax=axs[0], c='blue', linestyle='dashed')\n",
    "\n",
    "\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var2, ax=axs[1], c='red', s=10)\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth', ax=axs[1], c='red')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth2', ax=axs[1], c='red', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b120043-8edf-4c0f-8749-9d94319df955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot updated smooth with start of season (blue) and peak of season (red)\n",
    "plot = '15E_P3'\n",
    "var1 = 'NDTI'\n",
    "var2 = 'NDVI'\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 6), nrows=2)\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var1, ax=axs[0], c='blue', s=5)\n",
    "#df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth', ax=axs[0], c='blue')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth2', ax=axs[0], c='blue', linestyle='solid')\n",
    "\n",
    "\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var2, ax=axs[1], c='red', s=5)\n",
    "#df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth', ax=axs[1], c='red')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth2', ax=axs[1], c='red', linestyle='solid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6ed5f-2b2c-4445-b824-5f062446716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot updated smooth with start of season (blue) and peak of season (red)\n",
    "plot = '10S_P3'\n",
    "var1 = 'BAI_136'\n",
    "var2 = 'NDVI'\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 6), nrows=2)\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var1, ax=axs[0], c='blue', s=5)\n",
    "#df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth', ax=axs[0], c='blue')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var1 + '_smooth2', ax=axs[0], c='blue', linestyle='solid')\n",
    "\n",
    "\n",
    "df_ts[df_ts['Id'] == plot].plot.scatter(x='Date', y=var2, ax=axs[1], c='red', s=5)\n",
    "#df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth', ax=axs[1], c='red')\n",
    "df_ts[df_ts['Id'] == plot].plot(x='Date', y= var2 + '_smooth2', ax=axs[1], c='red', linestyle='solid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edcdf3-5d8b-4e4d-8d79-d4c9f263d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# rename smoothed columns and drop originals\n",
    "df_ts_out = df_ts.drop(columns=veg_list + band_list + ['_'.join([x, 'smooth']) for x in veg_list + band_list])\n",
    "col_rename_dict = {c: re.sub('_smooth2', '', c) for c in df_ts_out.columns if '_smooth2' in c}\n",
    "df_ts_out = df_ts_out.rename(columns=col_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ca294-1442-4e94-a069-28f643af486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "inDIR = '../data/training/'\n",
    "inFILE = 'vor_2013_2022_cln_2023_08_29_plot_hls_idxs.csv'\n",
    "inPATH = os.path.join(inDIR, inFILE)\n",
    "df_vor = pd.read_csv(inPATH, parse_dates=[2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901aead-4e6d-4535-b6d1-aacb1649150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vor_out = pd.merge(df_vor.drop(columns=veg_list + band_list), \n",
    "                     df_ts_out[['Id', 'Date'] + veg_list + band_list], \n",
    "                     on=['Id', 'Date'],\n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be7e7a-81e5-47cc-8e3b-444dd7852d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vor_out.to_csv(re.sub('.csv', '_test.csv', inPATH), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0f386-4225-4082-9760-fb0b7f537468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_nrt_env",
   "language": "python",
   "name": "hls_nrt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
